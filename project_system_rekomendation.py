# -*- coding: utf-8 -*-
"""project_system_rekomendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-S_4PVrfJ3UM5pXl6fDa3NsYM8B3OkYO

# Pendahuluan

Proyek ini bertujuan untuk membangun sistem rekomendasi film menggunakan dua pendekatan utama: Collaborative Filtering dan Content-Based Filtering. Dataset yang digunakan berasal dari Kaggle netflix movie rating dataset, yang terdiri dari data rating pengguna dan movie detail.

Sistem ini bertujuan untuk:

- Memberikan rekomendasi film yang relevan bagi pengguna berdasarkan riwayat rating mereka (Collaborative Filtering).

- Memberikan rekomendasi film berdasarkan kemiripan konten (judul) film (Content-Based Filtering).

# import
"""

!pip install numpy==1.24.4 scikit-surprise --force-reinstall

"""**Insight:** menginstall numpy dan scikit-surprise agar tidak conflict"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from surprise import Dataset, Reader, SVD
from surprise.model_selection import train_test_split
from surprise import accuracy
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel

"""**Insight:** Melakukan instalasi paket scikit-surprise untuk algoritma SVD dan import berbagai library untuk analisis data dan modelling."""

from google.colab import files
files.upload()  # upload kaggle.json kamu

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download kaggle dataset and unzip the file
# !cp kaggle.json ~/.kaggle/

# !chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d rishitjavia/netflix-movie-rating-dataset
!unzip netflix-movie-rating-dataset.zip

"""**Insight:**
Mengatur autentikasi dan mengunduh dataset Netflix dari Kaggle. File yang didapat terdiri dari Netflix_Dataset_Movie.csv dan Netflix_Dataset_Rating.csv.

# Data Loading

### Data Rating
"""

rating_df = pd.read_csv('/content/Netflix_Dataset_Rating.csv', header=0)
rating_df

"""**Insight:**
- Membaca file CSV berisi data rating ke dalam DataFrame.
-   Dataset memiliki 17770 baris (pengamatan) dan 3 kolom.
- User_ID adalah nomer penonton
- Rating adalah penilaian film dari 1-5
- Movie_ID adalah nomer film

### Data Movie
"""

movie_df = pd.read_csv('/content/Netflix_Dataset_Movie.csv', header=0)
movie_df

"""**Insight:**
- Membaca file CSV berisi data movie ke dalam DataFrame.
-   Dataset memiliki 17770 baris (pengamatan) dan 3 kolom.
- Name adalah nama film
- Year adalah tahun film
- Movie_ID adalah nomer film

# Data  Understading

### Data Rating
"""

rating_df.info()

"""
**Insight:** rating_df memiliki kolom User_ID, Rating, Movie_ID  dan ketganya memiliki type data int64

"""

rating_df.describe()

"""
**Insight:** rating_df memiliki kolom:
- Count: 17,3 juta rating dari ~2,65 juta pengguna untuk ~4.496 film.
- Mean: Rata-rata User_ID ~1,32 juta, rating 3,59 (skala 1-5), Movie_ID ~2.303.
- Std: Variasi User_ID 764.692, rating 1,06, Movie_ID 1.303, menunjukkan distribusi yang cukup merata.
- Min-Max: User_ID (6 - 2,65 juta), rating (1 - 5), Movie_ID (3 - 4.496).

"""

rating_df.nunique()

"""Fitur unik:
- User_ID:143458 data
- Rating: Skor penillaian 1-5.
- Movie_ID: 1350 data.

### Data Movie
"""

movie_df.info()

"""
**Insight:** movie_df memiliki kolom Movie_ID memiliki tipe data int64, Year memiliki tipe data int64, Name memiliki tipe data object
"""

movie_df.describe()

"""Insight:
- Count: 17.770 film.
- Mean: Movie_ID rata-rata 8.885,5; tahun rilis rata-rata 1990,24.
- Std: Variasi Movie_ID 5.129,9; tahun 16,56, menunjukkan sebaran luas.
- Min-Max: Movie_ID (1 - 17.770); tahun (1915 - 2005).
"""

movie_df.nunique()

"""Fitur:
- Movie_ID: 17770 data ID film.
- Year: 91 jumlah Tahun rilis.
- Name: 17297 data Judul film.
"""

movie_df['Name'].value_counts()

"""**Insight:** Jumlah data terbayak dari setiap data film"""

rating_df['Rating'].value_counts()

"""### Distribusi Data"""

# Distribusi rating
plt.figure(figsize=(8,5))
sns.histplot(rating_df['Rating'], bins=5)
plt.title('Distribusi Rating')
plt.xlabel('Rating')
plt.ylabel('Jumlah')
plt.show()

"""**Insight:** Jumlah distribusi data menunjukkan banyak data rating bintang 4"""

# Gabungkan file rating dan movie
rating_movie = rating_df.merge(movie_df, on='Movie_ID')

top_movies = movie_df['Name'].value_counts().head(10)

plt.figure(figsize=(12,6))
sns.barplot(x=top_movies.index, y=top_movies.values)
plt.title('Top 10 Film dengan jumlah terbanyak')
plt.xlabel('Film')
plt.xticks(rotation=60, ha='right')
plt.tight_layout()
plt.show()

"""**Insight:** Jumlah distribusi data film jumlah muncul terbanyak.

# Preprocessing

### Memeriksa Null value
"""

rating_df.isnull().sum()

"""**Insight:** tidak memiliki data yag kosong pada rating_df"""

movie_df.isnull().sum()

"""**Insight:**ternyata tidak memiliki data kosong pada movie_df

### Memeriksa dupliasi
"""

print(rating_df.duplicated().sum())

"""**Insight:**tidak ada data duplicate pada rating_df"""

print(movie_df.duplicated().sum())

"""**Insight:**tidak ada data duplicate pada movie_df

### Merge data
"""

df = pd.merge(rating_df, movie_df, on='Movie_ID')
df.head(10)

"""**Insight:**Menggbungan data rating_df dan movia_df dan menampilkan 10 data

### Prepare data
"""

# Gunakan hanya kolom yang dibutuhkan
data_df = df[['User_ID', 'Movie_ID', 'Rating']]

# Reader butuh tahu rentang rating
reader = Reader(rating_scale=(1, 5))

# Format data ke dalam objek Dataset surprise
data = Dataset.load_from_df(data_df, reader)

from surprise.model_selection import train_test_split

trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

"""**Insight:**Menyiapkan data untuk digunakan oleh library Surprise, termasuk membagi ke dalam data latih dan uji.

# Modelling

### Collaborative Filtering - SVD
"""

model = SVD(n_epochs=10,verbose = True)
model.fit(trainset)

"""**Insight**
Melatih model SVD dengan epoch=10 dan verbose true
"""

predictions = model.test(testset)

accuracy.rmse(predictions, verbose=True)

""" **Insight:** mengukur performanya menggunakan RMSE terhadap data uji."""

# Langkah 1: Ambil semua Movie_ID yang belum di-rating oleh user 712664
user_id = 2643029

# Movie yang sudah dirating oleh user ini
rated_movies = data_df[data_df['User_ID'] == user_id]['Movie_ID'].tolist()

# Movie yang belum dirating
all_movies = data_df['Movie_ID'].unique()
unrated_movies = [movie for movie in all_movies if movie not in rated_movies]

# Langkah 2: Prediksi rating untuk semua movie yang belum dirating
user_predictions = [model.predict(user_id, movie_id) for movie_id in unrated_movies]

# Langkah 3: Ambil top-N (misal 10) dengan rating tertinggi
top_n_preds = sorted(user_predictions, key=lambda x: x.est, reverse=True)[:10]

# Langkah 4: Ambil informasi judul dan tahun dari movie_df
top_n_result = []
for pred in top_n_preds:
    movie_info = movie_df[movie_df['Movie_ID'] == int(pred.iid)].iloc[0]
    top_n_result.append({
        'Year': movie_info['Year'],
        'Name': movie_info['Name'],
        'Estimated_Rating': round(pred.est, 4)
    })

# Langkah 5: Tampilkan hasil rekomendasi
top_n_df = pd.DataFrame(top_n_result)
print(top_n_df)

# Langkah 1: Ambil semua Movie_ID yang belum di-rating oleh user 712664
user_id = 43441

# Movie yang sudah dirating oleh user ini
rated_movies = data_df[data_df['User_ID'] == user_id]['Movie_ID'].tolist()

# Movie yang belum dirating
all_movies = data_df['Movie_ID'].unique()
unrated_movies = [movie for movie in all_movies if movie not in rated_movies]

# Langkah 2: Prediksi rating untuk semua movie yang belum dirating
user_predictions = [model.predict(user_id, movie_id) for movie_id in unrated_movies]

# Langkah 3: Ambil top-N (misal 10) dengan rating tertinggi
top_n_preds = sorted(user_predictions, key=lambda x: x.est, reverse=True)[:10]

# Langkah 4: Ambil informasi judul dan tahun dari movie_df
top_n_result = []
for pred in top_n_preds:
    movie_info = movie_df[movie_df['Movie_ID'] == int(pred.iid)].iloc[0]
    top_n_result.append({
        'Year': movie_info['Year'],
        'Name': movie_info['Name'],
        'Estimated_Rating': round(pred.est, 4)
    })

# Langkah 5: Tampilkan hasil rekomendasi
top_n_df = pd.DataFrame(top_n_result)
print(top_n_df)

"""**Insight**: Memprediksi rating untuk film yang belum ditonton oleh user, dan menampilkan rekomendasi 10 film terbaik.

### Evaluasi Collaborative Filtering - SVD
"""

rmse = accuracy.rmse(predictions)
mae = accuracy.mae(predictions)

print("RMSE:", rmse)
print("MAE:", mae)

"""**Insight:** Menghitung metrik RMSE dan MAE untuk mengevaluasi akurasi prediksi model Collaborative Filtering.

### Content-based Filtering
"""

# Pakai hanya film unik
movie_features = movie_df[['Movie_ID', 'Name']].drop_duplicates()
# Hilangkan nilai kosong (jika ada)
movie_features['Name'] = movie_features['Name'].fillna('')
movie_features.sample(5)

"""**Insight:** mengunakan nilai unik saja dan mengganti nilai Nan dengan nilai kosong"""

# Inisialisasi TF-IDF Vectorizer
tfidf = TfidfVectorizer(stop_words='english')

# Melakukan perhitungan idf pada data name
tfidf.fit(movie_features['Name'])

# Transform judul film ke TF-IDF matrix
tfidf_matrix = tfidf.fit_transform(movie_features['Name'])

# Hitung similarity antar film berdasarkan judul
cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)

"""**Insight:** Mengubah judul film menjadi representasi numerik menggunakan TF-IDF dan menghitung kesamaan antar film."""

# Index dataframe berdasarkan Movie_ID
indices = pd.Series(movie_features.index, index=movie_features['Movie_ID']).drop_duplicates()
movie_id_to_index = dict(zip(movie_features['Movie_ID'], movie_features.index))

"""**Insight:** Membuat Series yang memetakan Movie_ID ke indeks baris DataFrame movie_features, menghapus duplicate, dan Membuat kamus (dictionary) yang memetakan Movie_ID ke indeks baris DataFrame."""

def get_recommendations(movie_id, top_n=10):
    idx = movie_id_to_index.get(movie_id)
    if idx is None:
        return []

    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]

    # Ambil Movie_ID dan Judulnya
    movie_indices = [i[0] for i in sim_scores]
    result = movie_df.iloc[movie_indices][['Movie_ID', 'Name', 'Year']]
    result['Similarity'] = [i[1] for i in sim_scores]
    return result

"""**Insight:** Fungsi untuk menghasilkan 10 film yang paling mirip dengan film tertentu berdasarkan kemiripan judul."""

rekomendasi = get_recommendations(movie_id=3456, top_n=10)  # Ganti ID sesuai kebutuhan
print(rekomendasi)

"""**Insight:** menggunakan fungsi rekomendasi dengan movie_id= dan menampilkan 10 film"""

movie_df.loc[movie_df['Movie_ID'] == 3456, ['Name', 'Year']]

"""**Insight:** menampilkan nama movie_id dengan nomer 3456

### Evaluasi Model Content-based Filtering

*asasasas*
"""

!pip install fuzzywuzzy

"""**Insight:**
Menggunakan fuzzywuzzy untuk menghitung kesamaan nama antar film secara parsial. Ini digunakan sebagai ground truth untuk mengevaluasi seberapa akurat rekomendasi Content-Based berdasarkan judul mirip.


"""

from fuzzywuzzy import fuzz

# Pilih film acuan
reference_movie_id = 3456  # Movie_ID untuk "Lost: Season 1"
if reference_movie_id in movie_df['Movie_ID'].values:
    reference_idx = movie_id_to_index[reference_movie_id]
    reference_name = movie_df.loc[reference_idx, 'Name']
    print(f"Reference Movie ID: {reference_movie_id}, Name: {reference_name}")

    # Ground truth: film dengan skor kesamaan nama > 80
    # Gunakan apply untuk menghitung skor kesamaan untuk setiap judul
    similarity_scores = movie_df['Name'].apply(lambda x: fuzz.partial_ratio(x, reference_name))
    relevant_movies = set(movie_df[similarity_scores > 80]['Movie_ID'])
    print(f"Jumlah film relevan (nama mirip): {len(relevant_movies)}")

    # Dapatkan rekomendasi
    recommended_df = get_recommendations(reference_movie_id, top_n=10)
    print("Rekomendasi:", recommended_df)
    recommended = set(recommended_df['Movie_ID'])

    # Precision@k
    def precision_at_k(recommended, relevant, k):
        recommended_k = set(list(recommended)[:k])
        return len(recommended_k & relevant) / k if recommended_k else 0

    k = 10
    precision = precision_at_k(recommended, relevant_movies, k)
    print(f"Precision@{k}: {precision:.4f}")

    # Recall@k
    def recall_at_k(recommended, relevant, k):
        recommended_k = set(list(recommended)[:k])
        return len(recommended_k & relevant) / len(relevant) if relevant else 0

    k = 10
    recall = recall_at_k(recommended, relevant_movies, k)
    print(f"Recall@{k}: {recall:.4f}")

    # Hit Rate
    def hit_rate(recommended, relevant):
        return 1 if recommended & relevant else 0

    hit = hit_rate(recommended, relevant_movies)
    print(f"Hit Rate: {hit:.4f}")
else:
    print(f"Movie_ID {reference_movie_id} tidak ditemukan!")

"""**Insight:**
- Menentukan film yang dianggap relevan berdasarkan kemiripan judul ≥ 80 menggunakan metode partial_ratio dari fuzzy matching.
- Precision@k mengukur proporsi film yang direkomendasikan dalam top-k dan benar-benar relevan menurut fuzzy matching
- Recall@k mengukur proporsi film relevan yang berhasil ditangkap oleh sistem rekomendasi dalam top-k rekomendasi.
-Hit Rate bernilai 1 jika setidaknya satu film dalam rekomendasi termasuk dalam ground truth (film relevan).
"""

